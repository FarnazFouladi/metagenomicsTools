# my attempt at R code for Figure 2.1 in 4th edition of 
# elements of statistical learning

rm(list=ls())

numDataPoints <- 100

classBlue <- rnorm(10,mean=1);
classOrange <- rnorm(10);

blueDataX1 <- vector();
orangeDataX2 <- vector();
blueDataX2 <- vector();
orangeDataY<- vector();

for( i in 1:numDataPoints)
{
	blueDataX1[i] <- rnorm(1, mean=classBlue[ sample(1:10,1) ], sd = 1/5)
	orangeDataX2[i] <- rnorm(1, mean=classOrange[sample(1:10,1)],sd = 1/5)
	blueDataX2[i] <- rnorm(1, mean=classBlue[sample(1:10,1)],sd = 1/5)
	orangeDataY[i] <- rnorm(1, mean=classOrange[sample(1:10,1)],sd = 1/5)
}

colors <- c( rep("BLUE", numDataPoints), rep ("ORANGE", numDataPoints))
values <- c( rep(0, numDataPoints), rep (1, numDataPoints))

mergedDataX1 <- c(  blueDataX1, orangeDataX2 );
mergedDataX2 <-  c(  blueDataX2, orangeDataY);

plot(mergedDataX1, mergedDataX2, col=colors)

aLm <- lm( values ~ mergedDataX1 + mergedDataX2 )
summary(aLm)
coef(aLm)

decisionX <- seq( min(mergedDataX1), max(mergedDataX1), 0.001)
decisionY <- ( 0.5 - coef(aLm)[1] - coef(aLm)[2] * decisionX ) / coef(aLm)[3]
lines(decisionX, decisionY)

